{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0aee3dda",
   "metadata": {},
   "source": [
    "## Web Scrapping Busca Libre\n",
    "\n",
    "El siguiente cuaderno de Jupiter contiene un scrapping de datos desde el portal **www.buscalibre.cl** usando los paquetes `requests` y `html`. Además, se utiliza el paquete `Punctuation` para eliminar posibles puntuaciones en el ingreso de términos claves. Finalmente, se utiliza la biblioteca `pandas` para descargar los datos.\n",
    "\n",
    "Los códigos siguientes realizan una busqueda de libros de acuerdo con algún término clave y entrega una salida en `xlsx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad6ac44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar módulos\n",
    "import requests\n",
    "from punctuation import Punctuation\n",
    "import lxml.html as html\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc98093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_buscar_libro():\n",
    "    # url a buscalibre\n",
    "    url = \"https://www.buscalibre.cl/libros/search?q=\"\n",
    "    # Ingrese término a buscar\n",
    "    buscar = input('Ingrese lo que quiere buscar: ')\n",
    "    # Remover puntuaciones\n",
    "    buscar = Punctuation.remove(buscar)\n",
    "    # Unir termino de busqueda\n",
    "    buscar = \"+\".join(buscar.split())\n",
    "    # url\n",
    "    url = url+buscar\n",
    "    # Crear lista de datos vacia\n",
    "    autores_list = []\n",
    "    titulos_list = []\n",
    "    editoriales_list = []\n",
    "    descuentos_list = []\n",
    "    precios_anteriores_clp_list = []\n",
    "    precios_actuales_clp_list = []\n",
    "    paginas_webs_list = []\n",
    "\n",
    "    #Revisar correcta conexión a sitio web (Response [200] : Está OK)\n",
    "    obtener_pagina = requests.get(url)\n",
    "    obtener_pagina_utf8 = obtener_pagina.content.decode('utf-8')\n",
    "    parsear_pagina = html.fromstring(obtener_pagina_utf8)\n",
    "\n",
    "    for i in [1]+parsear_pagina.xpath('//span[@class=\"pagnLink\"]/a/text()'):\n",
    "        #Revisar correcta conexión a sitio web (Response [200] : Está OK)\n",
    "        obtener_pagina = requests.get(url+'&page='+str(i))\n",
    "        obtener_pagina_utf8 = obtener_pagina.content.decode('utf-8')\n",
    "        parsear_pagina = html.fromstring(obtener_pagina_utf8)\n",
    "\n",
    "        # Pasear autores\n",
    "        autores = parsear_pagina.xpath('//div[@class=\"autor\"]')\n",
    "        # Obtener texto de parseo autores\n",
    "        autores = [autore.text for autore in autores]\n",
    "        #autores_list.append(autores)\n",
    "\n",
    "        # Pasear títulos\n",
    "        titulos = parsear_pagina.xpath('//h3[@class=\"nombre margin-top-10 text-align-left\"]')\n",
    "        # Obtener texto de parseo títulos\n",
    "        titulos = [titulo.text for titulo in titulos]\n",
    "        # Quitar espacios en blanco\n",
    "        titulos = [titulo.strip() for titulo in titulos]\n",
    "        #titulos_list.append(titulos)\n",
    "\n",
    "        # Pasear editoriales\n",
    "        editoriales = parsear_pagina.xpath('//div[@class=\"autor color-dark-gray metas hide-on-hover\"]')\n",
    "        # Obtener texto de parseo editoriales\n",
    "        editoriales = [editorial.text for editorial in editoriales]\n",
    "        # Quitar espacios en blanco\n",
    "        editoriales = [editorial.strip() for editorial in editoriales]\n",
    "        #editoriales_list.append(editoriales)\n",
    "\n",
    "        # Pasear descuentos\n",
    "        descuentos = parsear_pagina.xpath('//div[@class=\"descuento-v2 color-white position-relative\"]')\n",
    "        # Obtener texto de parseo descuentos\n",
    "        descuentos = [descuento.text for descuento in descuentos]\n",
    "        #descuentos_list.append(descuentos)\n",
    "\n",
    "        # Pasear precios_anteriores\n",
    "        precios_anteriores = parsear_pagina.xpath('//p/del')\n",
    "        # Obtener texto de parseo precios_anteriores\n",
    "        precios_anteriores = [precio_anterior.text for precio_anterior in precios_anteriores]\n",
    "        # Tranformar a entero\n",
    "        precios_anteriores_clp = [int(precio.replace('$ ','').replace('.','')) if precio is not None else precio for precio in precios_anteriores ]\n",
    "        #precios_anteriores_clp_list.append(precios_anteriores_clp)\n",
    "\n",
    "        # Pasear precios_actuales\n",
    "        precios_actuales = parsear_pagina.xpath('//p/strong')\n",
    "        # Obtener texto de parseo precios_actuales\n",
    "        precios_actuales = [precio_actual.text for precio_actual in precios_actuales]\n",
    "        # Tranformar a entero\n",
    "        precios_actuales_clp = [int(precio.replace('$ ','').replace('.','')) if precio is not None else precio for precio in precios_actuales ]\n",
    "        #precios_actuales_clp_list.append(precios_actuales_clp)\n",
    "\n",
    "        # Pasear paginas_webs\n",
    "        paginas_webs = parsear_pagina.xpath('//*[@id=\"content\"]/div/div/a/@href')\n",
    "        #paginas_webs_list.append(paginas_webs)\n",
    "\n",
    "        autores_list.append(autores)\n",
    "        titulos_list.append(titulos)\n",
    "        editoriales_list.append(editoriales)\n",
    "        descuentos_list.append(descuentos)\n",
    "        precios_anteriores_clp_list.append(precios_anteriores_clp)\n",
    "        precios_actuales_clp_list.append(precios_actuales_clp)\n",
    "        paginas_webs_list.append(paginas_webs)\n",
    "    \n",
    "    df = pd.DataFrame({'autores' : [c for i in range(len(autores_list)) for c in autores_list[i]],\n",
    "                       'titulos' : [c for i in range(len(titulos_list)) for c in titulos_list[i]],\n",
    "                       'editoriales' : [c for i in range(len(editoriales_list)) for c in editoriales_list[i]],\n",
    "                       'descuentos':[c for i in range(len(descuentos_list)) for c in descuentos_list[i]],\n",
    "                       'precios_anteriores_clp':[c for i in range(len(precios_anteriores_clp_list)) for c in precios_anteriores_clp_list[i]],\n",
    "                       'precios_actuales_clp':[c for i in range(len(precios_actuales_clp_list)) for c in precios_actuales_clp_list[i]],\n",
    "                       'paginas_webs':[c for i in range(len(paginas_webs_list)) for c in paginas_webs_list[i]]}).sort_values('precios_actuales_clp')\n",
    "    \n",
    "    df.to_excel('../datos_salida/'+buscar+'.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6637d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_buscar_libro()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
